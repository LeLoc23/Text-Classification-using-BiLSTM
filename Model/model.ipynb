{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import underthesea\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    tokens = underthesea.word_tokenize(text)\n",
    "    # print(\"Lower\",tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(tokens):\n",
    "    with open(\"vietnamese-stopwords.txt\",\"r\",encoding=\"utf-8\") as file:\n",
    "        stopwords = file.readlines()\n",
    "    stopwords = [word.strip() for word in stopwords]\n",
    "    final_tokens = [token for token in tokens if token not in stopwords]\n",
    "    final_text = ' '.join(final_tokens)\n",
    "    # print(\"Stopword\",final_text)\n",
    "    return final_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Crawl/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4314 entries, 0 to 4313\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Danh mục  4314 non-null   object\n",
      " 1   Nội dung  4314 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 67.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Danh mục\n",
       "Xe          680\n",
       "Giới trẻ    562\n",
       "Văn hóa     548\n",
       "Thế giới    510\n",
       "Thời sự     380\n",
       "Kinh tế     295\n",
       "Sức khỏe    283\n",
       "Giáo dục    271\n",
       "Đời sống    250\n",
       "Thể thao    250\n",
       "Giải trí    147\n",
       "Du lịch     138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Danh mục'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4314 entries, 0 to 4313\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Danh mục  4314 non-null   object\n",
      " 1   Nội dung  4314 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 67.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=df['Nội dung'].apply(lambda x: lower_tokenize(x))\n",
    "content=content.apply(lambda x: remove_stopword(x))\n",
    "label=df['Danh mục']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       chiều thành ủy tphcm tổ chức phiên họp ban chỉ...\n",
       "1       xe tăng t nga khai hỏa ukraine khu vực công bố...\n",
       "2       pv thanh niên cơ quan chức năng hvĩnh thạnh xá...\n",
       "3       hội nghị thiếu tướng đào văn nhận phó tư lệnh ...\n",
       "4       afp đô đốc pierre vandier tổng tư lệnh quân đồ...\n",
       "                              ...                        \n",
       "4309    nhắc tuyên quang du khách du lịch khu di tích ...\n",
       "4310    trump hai thảo luận đồng thuận đàm phán thiết ...\n",
       "4311    bìa sách truyện thúy kiều tranh cãi thúy kiều ...\n",
       "4312    chàng trai quen biết hành động đẹp phụ nữ vn c...\n",
       "4313    messi khótheo báo tây ban nha marca đoạn clip ...\n",
       "Name: Nội dung, Length: 4314, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Thời sự\n",
       "1       Thế giới\n",
       "2        Thời sự\n",
       "3        Thời sự\n",
       "4       Thế giới\n",
       "          ...   \n",
       "4309     Du lịch\n",
       "4310    Thế giới\n",
       "4311     Văn hóa\n",
       "4312    Giới trẻ\n",
       "4313    Thể thao\n",
       "Name: Danh mục, Length: 4314, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(content, label, test_size=0.3, random_state=10)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "# Mã hóa nhãn mục tiêu\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3019, 5000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1295, 5000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Huấn luyện mô hình Naive Bayes\n",
    "MultiNB = naive_bayes.MultinomialNB(alpha=0.2)\n",
    "# fit the training dataset on the classifier\n",
    "MultiNB.fit(X_train_tfidf, y_train)\n",
    "# Dự đoán nhãn\n",
    "predictions_nb = MultiNB.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đánh giá bằng: Accuracy: 0.833976833976834\n",
      "Đánh giá bằng: Precision: 0.8493902827007022\n",
      "Đánh giá bằng: Recall: 0.833976833976834\n",
      "Đánh giá bằng: F1 Score: 0.8367126811828665\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(predictions_nb, y_test)\n",
    "print(f\"Đánh giá bằng: Accuracy: {accuracy}\")\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(predictions_nb, y_test, average='weighted')\n",
    "print(f\"Đánh giá bằng: Precision: {precision}\")\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(predictions_nb, y_test, average='weighted')\n",
    "print(f\"Đánh giá bằng: Recall: {recall}\")\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(predictions_nb, y_test, average='weighted')\n",
    "print(f\"Đánh giá bằng: F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nội dung:  học toán\n",
      "Dự đoán danh mục:  Giáo dục\n",
      "----------------------------------------\n",
      "Nội dung:  việt nam sân thắng lào tỉ số\n",
      "Dự đoán danh mục:  Thể thao\n",
      "----------------------------------------\n",
      "Nội dung:  bạo lực học đường\n",
      "Dự đoán danh mục:  Giới trẻ\n",
      "----------------------------------------\n",
      "Nội dung:  xe ariblade cc ngoại hình siêu đẹp\n",
      "Dự đoán danh mục:  Xe\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn bị dữ liệu kiểm thử mới\n",
    "new_data = [\"Tôi thích học Toán\",\n",
    "            \"VIệt Nam ra sân thắng Lào với tỉ số 10-0\",\n",
    "            \"Bạo lực học đường là vấn đề được quan tâm nhất hiện nay\",\n",
    "            \"Xe Ariblade 165CC có ngoại hình siêu đẹp\"]\n",
    "\n",
    "# Tiền xử lý dữ liệu kiểm thử mới\n",
    "new_data= [lower_tokenize(text) for text in new_data]\n",
    "new_data = [remove_stopword(tokens) for tokens in new_data] # Loại bỏ stop words\n",
    "# Chuyển đổi dữ liệu kiểm thử mới thành đặc trưng TF-IDF\n",
    "new_data_tfidf = tfidf_vectorizer.transform(new_data)\n",
    "\n",
    "# Dự đoán nhãn với dữ liệu kiểm thử mới\n",
    "new_predictions = MultiNB.predict(new_data_tfidf)\n",
    "\n",
    "# Chuyển đổi nhãn được dự đoán về dạng ban đầu\n",
    "new_predictions_labels = encoder.inverse_transform(new_predictions)\n",
    "# In ra các dự đoán\n",
    "for i, text in enumerate(new_data):\n",
    "    print(f\"Nội dung: \",text)\n",
    "    print(f\"Dự đoán danh mục: \",new_predictions_labels[i])\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((tfidf_vectorizer,MultiNB,encoder), \"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
