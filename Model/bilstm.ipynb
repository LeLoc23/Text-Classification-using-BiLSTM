{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "868178e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "import re\n",
    "import underthesea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a218489f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    tokens = underthesea.word_tokenize(text)\n",
    "    # print(\"Lower\",tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5765e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(tokens):\n",
    "    with open(\"vietnamese-stopwords.txt\",\"r\",encoding=\"utf-8\") as file:\n",
    "        stopwords = file.readlines()\n",
    "    stopwords = [word.strip() for word in stopwords]\n",
    "    final_tokens = [token for token in tokens if token not in stopwords]\n",
    "    final_text = ' '.join(final_tokens)\n",
    "    # print(\"Stopword\",final_text)\n",
    "    return final_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936777c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải dữ liệu\n",
    "data = pd.read_csv('../Crawl/Data1.csv')\n",
    "data = data.dropna(subset=['Nội dung', 'Danh mục'])\n",
    "data['tokens'] = data['Nội dung'].apply(lower_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a955fe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4314 entries, 0 to 4313\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Danh mục  4314 non-null   object\n",
      " 1   Nội dung  4314 non-null   object\n",
      " 2   tokens    4314 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 101.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd57b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Danh mục\n",
       "Xe          680\n",
       "Giới trẻ    562\n",
       "Văn hóa     548\n",
       "Thế giới    510\n",
       "Thời sự     380\n",
       "Kinh tế     295\n",
       "Sức khỏe    283\n",
       "Giáo dục    271\n",
       "Đời sống    250\n",
       "Thể thao    250\n",
       "Giải trí    147\n",
       "Du lịch     138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Danh mục'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87e086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4314 entries, 0 to 4313\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Danh mục  4314 non-null   object\n",
      " 1   Nội dung  4314 non-null   object\n",
      " 2   tokens    4314 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 101.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = data.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mã hóa nhãn\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Danh mục'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aeae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo vocab\n",
    "all_tokens = [token for tokens in df['tokens'] for token in tokens]\n",
    "vocab = {word: idx + 2 for idx, (word, _) in enumerate(Counter(all_tokens).items())}\n",
    "vocab['<PAD>'] = 0\n",
    "vocab['<UNK>'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac772ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển tokens thành ids\n",
    "def encode(tokens):\n",
    "    return [vocab.get(token, 1) for token in tokens]\n",
    "\n",
    "data['input_ids'] = data['tokens'].apply(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6185fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset PyTorch\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx]), torch.tensor(self.y[idx])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    inputs, labels = zip(*batch)\n",
    "    inputs = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    labels = torch.tensor(labels)\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cfe153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách tập train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['input_ids'].tolist(), y.tolist(), test_size=0.4, random_state=42)\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "test_dataset = TextDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mô hình BiLSTM với PyTorch\n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = lstm_out[:, -1, :]\n",
    "        out = self.dropout(out)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e54bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM(\n",
       "  (embedding): Embedding(100286, 128, padding_idx=0)\n",
       "  (lstm): LSTM(128, 64, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Khởi tạo mô hình\n",
    "vocab_size = len(vocab)\n",
    "embed_dim = 128\n",
    "hidden_dim = 64\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = BiLSTM(vocab_size, embed_dim, hidden_dim, num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d3561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 2.3613 - Accuracy: 0.1820\n",
      "Epoch 2/10 - Loss: 2.3586 - Accuracy: 0.1824\n",
      "Epoch 3/10 - Loss: 2.3552 - Accuracy: 0.1832\n",
      "Epoch 4/10 - Loss: 2.3479 - Accuracy: 0.1847\n",
      "Epoch 5/10 - Loss: 2.3410 - Accuracy: 0.1889\n",
      "Epoch 6/10 - Loss: 2.3387 - Accuracy: 0.1886\n",
      "Epoch 7/10 - Loss: 2.3402 - Accuracy: 0.1874\n",
      "Epoch 8/10 - Loss: 2.3382 - Accuracy: 0.1855\n",
      "Epoch 9/10 - Loss: 2.3548 - Accuracy: 0.1882\n",
      "Epoch 10/10 - Loss: 2.3285 - Accuracy: 0.1917\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.long()  # Ép kiểu sang LongTensor\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Lưu lại dự đoán và nhãn thật để tính accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Tính accuracy sau mỗi epoch\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f} - Accuracy: {acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1fb85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.1145\n",
      "Recall: 0.1547\n",
      "F1-score: 0.0516\n"
     ]
    }
   ],
   "source": [
    "# Tính precision, recall, f1-score\n",
    "model.eval()\n",
    "y_pred_labels = []\n",
    "y_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        y_pred_labels.extend(preds)\n",
    "        y_true_labels.extend(labels.numpy())\n",
    "\n",
    "precision = precision_score(y_true_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true_labels, y_pred_labels, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a850d94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nội dung: Xe máy CRB1000R vừa ra mắt mẫu mới\n",
      "→ Dự đoán danh mục: Xe\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Nội dung: Việt Nam ra sân thắng Lào với tỉ số 10-0\n",
      "→ Dự đoán danh mục: Xe\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Nội dung: Bạo lực học đường là vấn đề được quan tâm nhất hiện nay\n",
      "→ Dự đoán danh mục: Xe\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. Chuẩn bị mẫu dữ liệu cần kiểm thử\n",
    "sample_texts = [\n",
    "    \"Xe máy CRB1000R vừa ra mắt mẫu mới\",\n",
    "    \"Việt Nam ra sân thắng Lào với tỉ số 10-0\",\n",
    "    \"Bạo lực học đường là vấn đề được quan tâm nhất hiện nay\",\n",
    "    \n",
    "]\n",
    "\n",
    "# 2. Tiền xử lý: token hóa + loại bỏ stopword\n",
    "processed_samples = []\n",
    "for text in sample_texts:\n",
    "    tokens = lower_tokenize(text)\n",
    "    filtered_text = remove_stopword(tokens)\n",
    "    final_tokens = filtered_text.split()  # Chuyển lại thành list từ string sau khi remove_stopword\n",
    "    processed_samples.append(final_tokens)\n",
    "\n",
    "# 3. Mã hóa bằng vocab đã tạo\n",
    "encoded_samples = [torch.tensor(encode(tokens)) for tokens in processed_samples]\n",
    "\n",
    "# 4. Padding cho input\n",
    "padded_samples = pad_sequence(encoded_samples, batch_first=True, padding_value=0).to(device)\n",
    "\n",
    "# 5. Dự đoán\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(padded_samples)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "import joblib\n",
    "tfidf_vectorizer, MultiNB, label_encoder = joblib.load(\"model.joblib\")\n",
    "predicted_labels = label_encoder.inverse_transform(predictions.cpu().numpy())\n",
    "\n",
    "# 7. Hiển thị kết quả\n",
    "for text, label in zip(sample_texts, predicted_labels):\n",
    "    print(\"Nội dung:\", text)\n",
    "    print(\"→ Dự đoán danh mục:\", label)\n",
    "    print(\"-\" * 100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
